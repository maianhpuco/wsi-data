dataset_name: 'luad'
paths:
  source_dir: "/project/hnguyen2/mvu9/datasets/TCGA-datasets/LUAD"
  error_files: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/error_files.txt" 
  new_source_dir: "/project/hnguyen2/mvu9/datasets/processing_datasets/processing_tcga_256/luad/pyramidal_images"
  save_dir: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad"
  patch_h5_dir: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/patches_h5"
  patch_h5_dir_5x: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/patches_h5_5x"
  patch_h5_dir_10x: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/patches_h5_10x"
  # patch_png_dir: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/patches_png"
  patch_png_dir:
    patch_256x256_10x: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/png_patches/patch_256x256_10x"
    patch_256x256_5x:  "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/png_patches/patch_256x256_5x" 
  mask_save_dir: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/masks"
  only_mask_save_dir: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/only_masks"
  stitch_save_dir: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/graph_1024"
  slide_name_file: "/project/hnguyen2/mvu9/datasets/TCGA-metadata/LUAD/slides.xlsx"
  uuid_name_file: "/project/hnguyen2/mvu9/datasets/TCGA-metadata/LUAD/uuids.xlsx"
  preset_file: "/project/hnguyen2/mvu9/folder_04_ma/wsi-data/presets/tcga_vilamil.csv"
  manifest_dir: "/project/hnguyen2/mvu9/download_tcga/gdc-client/manifest/LUAD"

  # clip_rn50_features_path: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/clip_rn50_features" 
  # clip_rn50_features_path: 
  #   patch_256x256_10x: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/clip_rn50_features_fp/patch_256x256_10x" 
  #   patch_256x256_5x:  "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/clip_rn50_features_fp/patch_256x256_5x" 
  # conch_features_path: 
  #   patch_256x256_10x: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/conch_features_fp/patch_256x256_10x" 
  #   patch_256x256_5x:  "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/conch_features_fp/patch_256x256_5x" 
  # quilt_features_path: 
  #   patch_256x256_10x: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/quilt_features_fp/patch_256x256_10x" 
  #   patch_256x256_5x:  "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/quilt_features_fp/patch_256x256_5x" 
  clip_rn50_features_path: 
    patch_256x256_10x: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/clip_rn50_features_fp_clamver/patch_256x256_10x" 
    patch_256x256_5x:  "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/clip_rn50_features_fp_clamver/patch_256x256_5x" 
  
  conch_features_path: 
    patch_256x256_10x: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/conch_features_fp_clamver/patch_256x256_10x" 
    patch_256x256_5x:  "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/conch_features_fp_clamver/patch_256x256_5x"
      
  quilt_features_path: 
    patch_256x256_10x: "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/quilt_features_fp_clamver/patch_256x256_10x" 
    patch_256x256_5x:  "/project/hnguyen2/mvu9/processing_datasets/processing_tcga_256/luad/quilt_features_fp_clamver/patch_256x256_5x" 
   
# Processing parameters
processing:
  patch_size: 256
  step_size: 256
  patch_level: 0
  seg: true
  patch: true
  stitch: false
  auto_skip: true



clip_feature_extraction:
  model_name: clip_RN50  # or clip_ViTB32, resnet50_trunc, model_dino, etc.
  batch_size: 64 
  assets_dir: /project/hnguyen2/mvu9/pretrained_checkpoints  # only needed for DINO or other custom models ckpt_path = os.path.join(args.assets_dir, f'{args.model_name}.pth')
  cache_dir: /project/hnguyen2/mvu9/model_cache  # clip.load("ViT-B/32", download_root=args.cache_dir)
 

conch_feature_extraction:
  model_name:  "conch_ViT-B-16" 
  batch_size: 64
  target_patch_size: 224
  slide_ext: .svs
  no_auto_skip: false
  assets_dir:  /project/hnguyen2/mvu9/pretrained_checkpoints/conch_checkpoints/pytorch_model.bin

quilt_feature_extraction:
  model_name: quilt
  batch_size: 64
  target_patch_size: 224
  slide_ext: .svs
  no_auto_skip: false 
  assets_dir:  /project/hnguyen2/mvu9/pretrained_checkpoints/QuiltNet-B-32 
